{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textwrap import dedent\n",
    "\n",
    "from agno.agent import Agent, RunResponse\n",
    "from agno.models.google import Gemini\n",
    "from agno.models.openai import OpenAIResponses, OpenAIChat\n",
    "from agno.utils.pprint import pprint_run_response\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal\n",
    "from agno.tools.wikipedia import WikipediaTools\n",
    "from agno.tools.yfinance import YFinanceTools\n",
    "from agno.tools.arxiv import ArxivTools\n",
    "from agno.tools.duckduckgo import DuckDuckGoTools\n",
    "\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=OpenAIChat(id='gpt-4.1-mini')\n",
    "model_search=OpenAIChat(id='gpt-4o-mini-search-preview-2025-03-11')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "narrator_agent = Agent(\n",
    "    model=model,\n",
    "    tools=[\n",
    "        WikipediaTools()\n",
    "    ],\n",
    "    instructions=dedent(''),\n",
    "    show_tool_calls=True,\n",
    "    markdown=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e73cea083974463297574c795e29acee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ModelProviderError",
     "evalue": "Request too large for gpt-4.1-mini in project proj_kussjosP2TviqQ61bV9xtuP6 organization org-4LnERlibjecB6y66jgBJxKIp on tokens per min (TPM): Limit 200000, Requested 241895. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRateLimitError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\trading-llm\\Lib\\site-packages\\agno\\models\\openai\\chat.py:452\u001b[39m, in \u001b[36mOpenAIChat.invoke_stream\u001b[39m\u001b[34m(self, messages, response_format, tools, tool_choice)\u001b[39m\n\u001b[32m    451\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m452\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_client\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    453\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    454\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_format_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[32m    455\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    456\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minclude_usage\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_request_kwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    458\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    459\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m RateLimitError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\trading-llm\\Lib\\site-packages\\openai\\_utils\\_utils.py:287\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    286\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\trading-llm\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:925\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    924\u001b[39m validate_response_format(response_format)\n\u001b[32m--> \u001b[39m\u001b[32m925\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    926\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    927\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    933\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    937\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    938\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    939\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    940\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    941\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    949\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m    963\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    965\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    966\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    970\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\trading-llm\\Lib\\site-packages\\openai\\_base_client.py:1239\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1236\u001b[39m opts = FinalRequestOptions.construct(\n\u001b[32m   1237\u001b[39m     method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1238\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1239\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\trading-llm\\Lib\\site-packages\\openai\\_base_client.py:1034\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1033\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1034\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1036\u001b[39m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[31mRateLimitError\u001b[39m: Error code: 429 - {'error': {'message': 'Request too large for gpt-4.1-mini in project proj_kussjosP2TviqQ61bV9xtuP6 organization org-4LnERlibjecB6y66jgBJxKIp on tokens per min (TPM): Limit 200000, Requested 241895. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mModelProviderError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 154\u001b[39m\n\u001b[32m    116\u001b[39m fundamental_news_agent = Agent(\n\u001b[32m    117\u001b[39m     name=\u001b[33m\"\u001b[39m\u001b[33mFundamental News Analysis Specialist\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    118\u001b[39m     role=\u001b[33m\"\u001b[39m\u001b[33mPerform comprehensive fundamental news analysis\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    125\u001b[39m     ]\n\u001b[32m    126\u001b[39m )\n\u001b[32m    129\u001b[39m agent_team = Team(\n\u001b[32m    130\u001b[39m     name=\u001b[33m\"\u001b[39m\u001b[33mDiscussion Team\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    131\u001b[39m     mode=\u001b[33m\"\u001b[39m\u001b[33mcollaborate\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    151\u001b[39m     show_members_responses=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    152\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m \u001b[43magent_team\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprint_response\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mI want you to analyze ai sector. Choose the best value stocks  at the moment with very strong fundumentals and management. Timeline today.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_intermediate_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\trading-llm\\Lib\\site-packages\\agno\\team\\team.py:2002\u001b[39m, in \u001b[36mTeam.print_response\u001b[39m\u001b[34m(self, message, stream, stream_intermediate_steps, session_id, user_id, show_message, show_reasoning, show_full_reasoning, console, tags_to_include_in_markdown, audio, images, videos, files, markdown, knowledge_filters, **kwargs)\u001b[39m\n\u001b[32m   1999\u001b[39m     stream = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   2001\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[32m-> \u001b[39m\u001b[32m2002\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_print_response_stream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2003\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2004\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconsole\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconsole\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2005\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_message\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_message\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2006\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_reasoning\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_reasoning\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2007\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_full_reasoning\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_full_reasoning\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2008\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtags_to_include_in_markdown\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtags_to_include_in_markdown\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2009\u001b[39m \u001b[43m        \u001b[49m\u001b[43msession_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43msession_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2010\u001b[39m \u001b[43m        \u001b[49m\u001b[43muser_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2011\u001b[39m \u001b[43m        \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m=\u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2012\u001b[39m \u001b[43m        \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2013\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvideos\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvideos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2014\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2015\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmarkdown\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmarkdown\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2016\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_intermediate_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_intermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2017\u001b[39m \u001b[43m        \u001b[49m\u001b[43mknowledge_filters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mknowledge_filters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2018\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2019\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2020\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2021\u001b[39m     \u001b[38;5;28mself\u001b[39m._print_response(\n\u001b[32m   2022\u001b[39m         message=message,\n\u001b[32m   2023\u001b[39m         console=console,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2036\u001b[39m         **kwargs,\n\u001b[32m   2037\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\trading-llm\\Lib\\site-packages\\agno\\team\\team.py:2410\u001b[39m, in \u001b[36mTeam._print_response_stream\u001b[39m\u001b[34m(self, message, console, show_message, show_reasoning, show_full_reasoning, tags_to_include_in_markdown, session_id, user_id, audio, images, videos, files, markdown, stream_intermediate_steps, knowledge_filters, **kwargs)\u001b[39m\n\u001b[32m   2407\u001b[39m \u001b[38;5;66;03m# Dict to track member response panels by member_id\u001b[39;00m\n\u001b[32m   2408\u001b[39m member_response_panels = {}\n\u001b[32m-> \u001b[39m\u001b[32m2410\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2411\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mteam_markdown\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[32m   2412\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmarkdown\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\trading-llm\\Lib\\site-packages\\agno\\team\\team.py:950\u001b[39m, in \u001b[36mTeam._run_stream\u001b[39m\u001b[34m(self, run_response, run_messages, session_id, user_id, response_format, stream_intermediate_steps)\u001b[39m\n\u001b[32m    947\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m._create_run_response(content=\u001b[33m\"\u001b[39m\u001b[33mRun started\u001b[39m\u001b[33m\"\u001b[39m, event=RunEvent.run_started, session_id=session_id)\n\u001b[32m    949\u001b[39m \u001b[38;5;66;03m# 2. Get a response from the model\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m950\u001b[39m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._handle_model_response_stream(\n\u001b[32m    951\u001b[39m     run_response=run_response,\n\u001b[32m    952\u001b[39m     run_messages=run_messages,\n\u001b[32m    953\u001b[39m     session_id=session_id,\n\u001b[32m    954\u001b[39m     response_format=response_format,\n\u001b[32m    955\u001b[39m     stream_intermediate_steps=stream_intermediate_steps,\n\u001b[32m    956\u001b[39m )\n\u001b[32m    958\u001b[39m \u001b[38;5;66;03m# 3. Update Team Memory\u001b[39;00m\n\u001b[32m    959\u001b[39m \u001b[38;5;28mself\u001b[39m._update_memory(\n\u001b[32m    960\u001b[39m     run_response=run_response,\n\u001b[32m    961\u001b[39m     run_messages=run_messages,\n\u001b[32m   (...)\u001b[39m\u001b[32m    964\u001b[39m     index_of_last_user_message=index_of_last_user_message,\n\u001b[32m    965\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\trading-llm\\Lib\\site-packages\\agno\\team\\team.py:1618\u001b[39m, in \u001b[36mTeam._handle_model_response_stream\u001b[39m\u001b[34m(self, run_response, run_messages, session_id, response_format, stream_intermediate_steps)\u001b[39m\n\u001b[32m   1612\u001b[39m reasoning_state = {\n\u001b[32m   1613\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mreasoning_started\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   1614\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mreasoning_time_taken\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m0.0\u001b[39m,\n\u001b[32m   1615\u001b[39m }\n\u001b[32m   1617\u001b[39m full_model_response = ModelResponse()\n\u001b[32m-> \u001b[39m\u001b[32m1618\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel_response_chunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresponse_stream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1619\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_messages\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1620\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1621\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_tools_for_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1622\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_functions_for_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1623\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1624\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtool_call_limit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtool_call_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1625\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1626\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle_model_response_chunk\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1627\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrun_response\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_response\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1628\u001b[39m \u001b[43m        \u001b[49m\u001b[43msession_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43msession_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1632\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreasoning_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreasoning_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1633\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1635\u001b[39m \u001b[38;5;66;03m# 3. Update TeamRunResponse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\trading-llm\\Lib\\site-packages\\agno\\models\\base.py:724\u001b[39m, in \u001b[36mModel.response_stream\u001b[39m\u001b[34m(self, messages, response_format, tools, functions, tool_choice, tool_call_limit)\u001b[39m\n\u001b[32m    722\u001b[39m \u001b[38;5;66;03m# Generate response\u001b[39;00m\n\u001b[32m    723\u001b[39m assistant_message.metrics.start_timer()\n\u001b[32m--> \u001b[39m\u001b[32m724\u001b[39m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.process_response_stream(\n\u001b[32m    725\u001b[39m     messages=messages,\n\u001b[32m    726\u001b[39m     assistant_message=assistant_message,\n\u001b[32m    727\u001b[39m     stream_data=stream_data,\n\u001b[32m    728\u001b[39m     response_format=response_format,\n\u001b[32m    729\u001b[39m     tools=tools,\n\u001b[32m    730\u001b[39m     tool_choice=tool_choice \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tool_choice,\n\u001b[32m    731\u001b[39m )\n\u001b[32m    732\u001b[39m assistant_message.metrics.stop_timer()\n\u001b[32m    734\u001b[39m \u001b[38;5;66;03m# Populate assistant message from stream data\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\trading-llm\\Lib\\site-packages\\agno\\models\\base.py:689\u001b[39m, in \u001b[36mModel.process_response_stream\u001b[39m\u001b[34m(self, messages, assistant_message, stream_data, response_format, tools, tool_choice)\u001b[39m\n\u001b[32m    677\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mprocess_response_stream\u001b[39m(\n\u001b[32m    678\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    679\u001b[39m     messages: List[Message],\n\u001b[32m   (...)\u001b[39m\u001b[32m    684\u001b[39m     tool_choice: Optional[Union[\u001b[38;5;28mstr\u001b[39m, Dict[\u001b[38;5;28mstr\u001b[39m, Any]]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    685\u001b[39m ) -> Iterator[ModelResponse]:\n\u001b[32m    686\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    687\u001b[39m \u001b[33;03m    Process a streaming response from the model.\u001b[39;00m\n\u001b[32m    688\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m689\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresponse_delta\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minvoke_stream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    690\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    691\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    692\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    693\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_tool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    694\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    695\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_response_delta\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparse_provider_response_delta\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_delta\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    696\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_populate_stream_data_and_assistant_message\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    697\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstream_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43massistant_message\u001b[49m\u001b[43m=\u001b[49m\u001b[43massistant_message\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_response_delta\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_response_delta\u001b[49m\n\u001b[32m    698\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\trading-llm\\Lib\\site-packages\\agno\\models\\openai\\chat.py:467\u001b[39m, in \u001b[36mOpenAIChat.invoke_stream\u001b[39m\u001b[34m(self, messages, response_format, tools, tool_choice)\u001b[39m\n\u001b[32m    461\u001b[39m     error_message = e.response.json().get(\u001b[33m\"\u001b[39m\u001b[33merror\u001b[39m\u001b[33m\"\u001b[39m, {})\n\u001b[32m    462\u001b[39m     error_message = (\n\u001b[32m    463\u001b[39m         error_message.get(\u001b[33m\"\u001b[39m\u001b[33mmessage\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mUnknown model error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    464\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(error_message, \u001b[38;5;28mdict\u001b[39m)\n\u001b[32m    465\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m error_message\n\u001b[32m    466\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m467\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ModelProviderError(\n\u001b[32m    468\u001b[39m         message=error_message,\n\u001b[32m    469\u001b[39m         status_code=e.response.status_code,\n\u001b[32m    470\u001b[39m         model_name=\u001b[38;5;28mself\u001b[39m.name,\n\u001b[32m    471\u001b[39m         model_id=\u001b[38;5;28mself\u001b[39m.id,\n\u001b[32m    472\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    473\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m APIConnectionError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    474\u001b[39m     log_error(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAPI connection error from OpenAI API: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mModelProviderError\u001b[39m: Request too large for gpt-4.1-mini in project proj_kussjosP2TviqQ61bV9xtuP6 organization org-4LnERlibjecB6y66jgBJxKIp on tokens per min (TPM): Limit 200000, Requested 241895. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more."
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from textwrap import dedent\n",
    "\n",
    "from agno.agent import Agent\n",
    "from agno.models.openai import OpenAIChat\n",
    "from agno.team.team import Team\n",
    "from agno.tools.arxiv import ArxivTools\n",
    "from agno.tools.duckduckgo import DuckDuckGoTools\n",
    "from agno.tools.googlesearch import GoogleSearchTools\n",
    "from agno.tools.hackernews import HackerNewsTools\n",
    "\n",
    "reddit_researcher = Agent(\n",
    "    name=\"Reddit Researcher\",\n",
    "    role=\"Research a topic on Reddit\",\n",
    "    model=model_search,\n",
    "    add_name_to_instructions=True,\n",
    "    instructions=dedent(\"\"\"\n",
    "    You are a Reddit researcher.\n",
    "    You will be given a topic to research on Reddit.\n",
    "    You will need to find the most relevant posts on Reddit and comments on the posts.\n",
    "    \"\"\"),\n",
    ")\n",
    "\n",
    "reddit_agent = Agent(\n",
    "    name=\"Social Media Sentiment Analyzer\",\n",
    "    role=\"Analyze reddit media sentiment and retail investor behavior\",\n",
    "    model=model_search,\n",
    "    instructions=[\n",
    "        \"Search Reddit stock discussions\",\n",
    "        \"Extract sentiment scores and trend analysis\",\n",
    "        \"Identify momentum indicators and retail investor behavior\",\n",
    "        \"Distinguish between informed analysis and meme stock speculation\",\n",
    "        \"Provide sentiment percentages and confidence levels\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "trump_agent = Agent(\n",
    "    name=\"Social Media Sentiment Analyzer\",\n",
    "    role=\"Analyze Truth Social media sentiment and retail investor behavior\",\n",
    "    model=model_search,\n",
    "    instructions=[\n",
    "        \"Search Truth Social stock discussions\",\n",
    "        \"Extract sentiment scores and trend analysis\",\n",
    "        \"Identify momentum indicators and retail investor behavior\",\n",
    "        \"Distinguish between informed analysis and meme stock speculation\",\n",
    "        \"Provide sentiment percentages and confidence levels\",\n",
    "        \"Espesially focus on the sentiment of the posts and comments of Donald Trump and his team\",\n",
    "        \"You will need to find trending discussions, influential voices, and real-time updates.\",\n",
    "        \"Focus on verified accounts and credible sources when possible.\",\n",
    "        \"Track relevant hashtags and ongoing conversations.\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "twitter_agent = Agent(\n",
    "    name=\"Social Media Sentiment Analyzer\",\n",
    "    role=\"Analyze twitter media sentiment and retail investor behavior\",\n",
    "    model=model_search,\n",
    "    instructions=[\n",
    "        \"Search twitter stock discussions\",\n",
    "        \"Extract sentiment scores and trend analysis\",\n",
    "        \"Identify momentum indicators and retail investor behavior\",\n",
    "        \"Distinguish between informed analysis and meme stock speculation\",\n",
    "        \"Provide sentiment percentages and confidence levels\",\n",
    "        \"Espesially focus on the sentiment of the posts and comments of Elon Musk and his team\",\n",
    "        \"You will need to find trending discussions, influential voices, and real-time updates.\",\n",
    "        \"Focus on verified accounts and credible sources when possible.\",\n",
    "        \"Track relevant hashtags and ongoing conversations.\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "academic_paper_researcher = Agent(\n",
    "    name=\"Academic Paper Researcher\",\n",
    "    model=model,\n",
    "    role=\"Research academic papers and scholarly content\",\n",
    "    tools=[ArxivTools(), GoogleSearchTools()],\n",
    "    add_name_to_instructions=True,\n",
    "    instructions=dedent(\"\"\"\n",
    "    You are a academic paper researcher.\n",
    "    You will be given a topic to research in academic literature.\n",
    "    You will need to find relevant scholarly articles, papers, and academic discussions.\n",
    "    Focus on peer-reviewed content and citations from reputable sources.\n",
    "    Provide brief summaries of key findings and methodologies.\n",
    "    \"\"\"),\n",
    ")\n",
    "\n",
    "twitter_researcher = Agent(\n",
    "    name=\"Twitter Researcher\",\n",
    "    model=model_search,\n",
    "    role=\"Research trending discussions and real-time updates\",\n",
    "    add_name_to_instructions=True,\n",
    "    instructions=dedent(\"\"\"\n",
    "    You are a Twitter/X researcher.\n",
    "    You will be given a topic to research on Twitter/X.\n",
    "    You will need to find trending discussions, influential voices, and real-time updates.\n",
    "    Focus on verified accounts and credible sources when possible.\n",
    "    Track relevant hashtags and ongoing conversations.\n",
    "    \"\"\"),\n",
    ")\n",
    "\n",
    "fundamental_agent = Agent(\n",
    "    name=\"Fundamental Analysis Specialist\",\n",
    "    role=\"Perform comprehensive fundamental analysis\",\n",
    "    model=model,\n",
    "    tools=[YFinanceTools(\n",
    "        enable_all=True\n",
    "    )],\n",
    "    instructions=[\n",
    "        \"Analyze revenue growth, profitability metrics, and valuation ratios\",\n",
    "        \"Evaluate debt levels, cash flow, and balance sheet strength\",\n",
    "        \"Compare metrics against industry benchmarks\",\n",
    "        \"Identify fundamental catalysts and risk factors\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "fundamental_news_agent = Agent(\n",
    "    name=\"Fundamental News Analysis Specialist\",\n",
    "    role=\"Perform comprehensive fundamental news analysis\",\n",
    "    model=model_search,\n",
    "    instructions=[\n",
    "        \"Analyze revenue growth, profitability metrics, and valuation ratios\",\n",
    "        \"Evaluate debt levels, cash flow, and balance sheet strength\",\n",
    "        \"Compare metrics against industry benchmarks\",\n",
    "        \"Identify fundamental catalysts and risk factors\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "agent_team = Team(\n",
    "    name=\"Discussion Team\",\n",
    "    mode=\"collaborate\",\n",
    "    model=model,\n",
    "    members=[\n",
    "        reddit_agent,\n",
    "        twitter_agent,\n",
    "        trump_agent,\n",
    "        fundamental_agent,\n",
    "        fundamental_news_agent\n",
    "    ],\n",
    "    instructions=[\n",
    "        \"You are stock expert master.\",\n",
    "        \"You are a stock expert and you will be given a stock to analyze.\",\n",
    "        \"You will need to analyze the stock or a topic and provide a recommendation.\",\n",
    "        \"You will need to use the tools provided to you to analyze the stock or a topic.\",\n",
    "        \"Provide numbers and a reccomendation buy, hold, sell in the end\"\n",
    "    ],\n",
    "   # success_criteria=\"The team has reached a consensus.\",\n",
    "    enable_agentic_context=True,\n",
    "    show_tool_calls=True,\n",
    "    markdown=True,\n",
    "    show_members_responses=True,\n",
    ")\n",
    "\n",
    "agent_team.print_response(\n",
    "    message=\"I want you to analyze ai sector. Choose the best value stocks  at the moment with very strong fundumentals and management. Timeline today.\",\n",
    "    stream=True,\n",
    "    stream_intermediate_steps=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trading-llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
